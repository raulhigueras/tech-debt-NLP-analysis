{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "path = \"../data/raw/td_V2.db\"\n",
    "con = sqlite3.connect(path)\n",
    "\n",
    "jira_query = \"\"\"SELECT *\n",
    "     FROM jira_issues\"\"\"\n",
    "\n",
    "jira = pd.read_sql(jira_query, con)\n",
    "description = jira['DESCRIPTION']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unifying style"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert all text to lowercase"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "description_1 = description.apply( lambda txt: txt.lower() )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove symbols:\n",
    "- Remove special characters (\\r and \\n)\n",
    "- Remove text in {} and []\n",
    "- Special words (VERSION, URL, PATH, FILE, DATE)\n",
    "- Remove punctuation\n",
    "- Replace multiple spaces for a single space"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "brackets_re = r'\\[+(.*?)\\]+|\\{+(.*?)\\}+'\n",
    "URL_re = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
    "PATH_re = r'(\\/)*[\\w\\-\\_.\\<\\>]+(\\/[\\w\\-\\_.\\<\\>\\=]+)+'\n",
    "version_re = r'\\d+(\\.\\d+)+'\n",
    "file_re = r'[\\w\\-\\_]+(\\.[\\w\\-\\_\\=]+)+'\n",
    "date_re = r'(?:(?:31(\\/|-|\\.)(?:0?[13578]|1[02]|(?:Jan|Mar|May|Jul|Aug|Oct|Dec)))\\1|(?:(?:29|30)(\\/|-|\\.)(?:0?[1,3-9]|1[0-2]|(?:Jan|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))\\2))(?:(?:1[6-9]|[2-9]\\d)?\\d{2})$|^(?:29(\\/|-|\\.)(?:0?2|(?:Feb))\\3(?:(?:(?:1[6-9]|[2-9]\\d)?(?:0[48]|[2468][048]|[13579][26])|(?:(?:16|[2468][048]|[3579][26])00))))$|^(?:0?[1-9]|1\\d|2[0-8])(\\/|-|\\.)(?:(?:0?[1-9]|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep))|(?:1[0-2]|(?:Oct|Nov|Dec)))\\4(?:(?:1[6-9]|[2-9]\\d)?\\d{2})'\n",
    "punctuation_re = r'[^\\w\\s]'\n",
    "multiplespace_re = r'  +'\n",
    "\n",
    "description_2 = description_1.apply( lambda txt: txt.replace('\\r', ' '))\n",
    "description_2 = description_2.apply( lambda txt: txt.replace('\\n', ' '))\n",
    "description_2 = description_2.apply( lambda txt: re.sub(brackets_re, '', txt) )\n",
    "description_2 = description_2.apply( lambda txt: re.sub(URL_re, 'URL', txt) )\n",
    "description_2 = description_2.apply( lambda txt: re.sub(PATH_re, 'PATH', txt) )\n",
    "description_2 = description_2.apply( lambda txt: re.sub(version_re, 'VERSION', txt) )\n",
    "description_2 = description_2.apply( lambda txt: re.sub(file_re, 'FILE', txt) )\n",
    "description_2 = description_2.apply( lambda txt: re.sub(date_re, 'DATE', txt) )\n",
    "description_2 = description_2.apply( lambda txt: re.sub(punctuation_re, ' ', txt) )\n",
    "description_2 = description_2.apply( lambda txt: re.sub(multiplespace_re, ' ', txt) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stopword removal\n",
    "Three steps:\n",
    "1. Tokeanization\n",
    "2. Stopword removal\n",
    "3. Join string"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/raulhigueras/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/raulhigueras/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "words = [word_tokenize(description_2[i]) for i in range(len(description_2))]\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "words_wo_sw = [[word for word in txt if word not in sw] for txt in words]\n",
    "description_3 = pd.Series([' '.join(txt) for txt in words_wo_sw])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project-specific terms removal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "project_names = {\" \" + name.split(\":\")[-1].replace(\"-\", \" \") + \" \" for name in set(jira['PROJECT_ID']) }\n",
    "project_names_re = r'|'.join(project_names)\n",
    "description_4 = description_3.apply( lambda txt: re.sub(project_names_re, ' ', txt) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some examples\n",
    "Following, we show two examples of preprocessing. Each example is composed of four strings, the starting description and each one of the processing steps' output. Both examples have been chosen to show how the code works."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "idx = 10050\n",
    "\n",
    "print(description_1[idx], end=\"\\n----\\n\")\n",
    "print(description_2[idx], end=\"\\n----\\n\")\n",
    "print(description_3[idx], end=\"\\n----\\n\")\n",
    "print(description_4[idx], end=\"\\n----\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "there are a bunch of files who have either a plain wrong number or at least something that is not really consistent with https://thrift.apache.org/docs/committers/howtoversion \n",
      "\n",
      "additionally, the doap.rdf is slightly outdated.\n",
      "----\n",
      "there are a bunch of files who have either a plain wrong number or at least something that is not really consistent with URL additionally the FILE is slightly outdated \n",
      "----\n",
      "bunch files either plain wrong number least something really consistent URL additionally FILE slightly outdated\n",
      "----\n",
      "bunch files either plain wrong number least something really consistent URL additionally FILE slightly outdated\n",
      "----\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "idx = 9643\n",
    "\n",
    "print(description_1[idx], end=\"\\n----\\n\")\n",
    "print(description_2[idx], end=\"\\n----\\n\")\n",
    "print(description_3[idx], end=\"\\n----\\n\")\n",
    "print(description_4[idx], end=\"\\n----\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "when using thttpclient to establish authenticated connections over http, it should be responsible for saving the cookie sent by the server in the set-cookie response header.\n",
      "\n",
      "for example, this is useful when using thrift to establish a connection with a hive server exposing thrift over http with authentication activated (regardless of the mechanism).\n",
      "----\n",
      "when using thttpclient to establish authenticated connections over http it should be responsible for saving the cookie sent by the server in the set cookie response header for example this is useful when using thrift to establish a connection with a hive server exposing thrift over http with authentication activated regardless of the mechanism \n",
      "----\n",
      "using thttpclient establish authenticated connections http responsible saving cookie sent server set cookie response header example useful using thrift establish connection hive server exposing thrift http authentication activated regardless mechanism\n",
      "----\n",
      "using thttpclient establish authenticated connections http responsible saving cookie sent server set cookie response header example useful using establish connection server exposing http authentication activated regardless mechanism\n",
      "----\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Next Step: Modeling\n",
    "Two different sections.\n",
    "1. **Feature extraction:** word embeddings, tf-idf, etc.\n",
    "2. **Model design:** clustering, classificators, etc."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}